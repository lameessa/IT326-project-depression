{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# IT326 Project - Phase1",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Depression ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### \"Depression (also known as major depression, major depressive disorder, or clinical depression) is a common but serious mood disorder. It causes severe symptoms that affect how a person feels, thinks, and handles daily activities, such as sleeping, eating, or working\".",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### The goal",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### The goal of this project is to use data mining techniques to explore how various aspects of life influence depression and how these factors interact with each other. We will focus on factors such as age, gender, marital status, and socioeconomic status, among others. By applying classification and clustering methods, we aim to reveal the connections between these factors and predicting depression, ultimately helping us gain better insights to support affected individuals.\n",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": "### General information about the dataset:",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### The dataset contains comprehensive data aimed at analyzing depression and its related factors. It includes various attributes that can be used to study the depression status of individuals.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv('b_depressed.csv')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "num_attributes = len(df.columns)\nattribute_types = df.dtypes.to_frame().rename(columns={0: 'Data Types'})\nnum_objects = len(df)\nclass_name = df.columns[-1]  \n\ntext3= \"Number of attributes:\"\nbold_text3 = \"\\033[1m\" + text3 + \"\\033[0m\"\nprint(bold_text3, num_attributes)\nprint(\"\\n\")\n\ntext4= \"Attribute types:\"\nbold_text4 = \"\\033[1m\" + text4 + \"\\033[0m\"\nprint(bold_text4)\nprint(attribute_types)\nprint(\"\\n\")\n\ntext5= \"Number of objects:\"\nbold_text5 = \"\\033[1m\" + text5 + \"\\033[0m\"\nprint(bold_text5, num_objects)\nprint(\"\\n\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1mNumber of attributes:\u001b[0m 23\n\n\n\u001b[1mAttribute types:\u001b[0m\n                      Data Types\nSurvey_id                  int64\nVille_id                   int64\nsex                        int64\nAge                        int64\nMarried                    int64\nNumber_children            int64\neducation_level            int64\ntotal_members              int64\ngained_asset               int64\ndurable_asset              int64\nsave_asset                 int64\nliving_expenses            int64\nother_expenses             int64\nincoming_salary            int64\nincoming_own_farm          int64\nincoming_business          int64\nincoming_no_business       int64\nincoming_agricultural      int64\nfarm_expenses              int64\nlabor_primary              int64\nlasting_investment         int64\nno_lasting_investmen     float64\ndepressed                  int64\n\n\n\u001b[1mNumber of objects:\u001b[0m 1429\n\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "####\nAttributes: The dataset contains multiple features related to depression such as:\n1. Survey_id: A unique identifier for each respondent in the dataset.\n2. Ville_id: Refers to the ID of the respondent's village or town.\n3. sex: The gender of the respondent as 0 (male) or 1 (female).\n4. Age: The age of the respondent in years.\n5. Married: Indicates the marital status of the respondent, often coded as 0 (unmarried) or 1 (married).\n6. Number_children: The total number of children the respondent has.\n7. education_level: The highest level of education attained by the respondent, which could be categorized as primary, secondary, or higher education.\n8. total_members: The number of members in the respondent's household, indicating family size.\n9. gained_asset: The assets gained by the respondent or household, possibly indicating economic progress.\n10. durable_asset: The ownership of durable assets like cars, appliances, etc.\n11. save_asset: The amount or presence of savings or financial assets held by the respondent.\n12. living_expenses: The monthly or yearly expenses for basic living needs (e.g., food, housing).\n13. other_expenses: Expenses beyond basic needs, such as entertainment or leisure activities.\n14. incoming_salary: The salary or wage income the respondent receives from employment.\n15. incoming_own_farm: Income derived from the respondent’s own farming activities.\n16. incoming_business: Income generated from the respondent’s business operations.\n17. incoming_no_business: Income from non-business sources (could include pensions, government aid, etc.).\n18. incoming_agricultural: Income from agricultural activities, possibly farming or livestock.\n19. farm_expenses: Expenses related to maintaining or operating a farm.\n20. labor_primary: The labor status of the respondent, whether they are the primary laborer in their household or community.\n21. lasting_investment: Investments made by the respondent in long-term assets or financial ventures.\n22. no_lasting_investment: Lack of or absence of long-term investments.\n23. depressed: The target variable indicating whether the respondent is depressed, labeled as 0 for \"Not Depressed\" and 1 for \"Depressed\". This binary attribute is the class label of the dataset, used for classification tasks.\n\nData type: The dataset features quantitative and qualitative attributes, including numeric and categorical variables.\n\nNumber of records (objects): The dataset consists of approximately 1429 data entries.\n\nClass labels: The dataset is focused on detecting whether a person is depressed, often using binary labels like 1 \"Depressed\" and 0 \"Not Depressed\" based on various assessments.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Source of dataset",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "###### https://www.kaggle.com/datasets/diegobabativa/depression?resource=download ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\n\n\n# Step 1: Fill missing values in 'no_lasting_investmen' with the mean\nimputer = SimpleImputer(strategy='mean')\ndf['no_lasting_investmen'] = imputer.fit_transform(df[['no_lasting_investmen']])\n\n# Step 2: Discretize 'Age' into 'Youth', 'Adult', 'Senior'\nage_bins = [0, 24, 59, float('inf')]\nage_labels = ['Youth', 'Adult', 'Senior']\ndf['Age_group'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=True)\n\n# Step 3: Scale other numerical features using MinMaxScaler\nnumerical_features = ['incoming_salary', 'incoming_own_farm', \n                      'incoming_business', 'incoming_no_business', 'incoming_agricultural', \n                      'labor_primary', 'lasting_investment', 'no_lasting_investmen', 'total_assets', 'total_expenses']\n\nscaler = MinMaxScaler()\ndf[numerical_features] = scaler.fit_transform(df[numerical_features])\n\n# Step 4: One-hot encode categorical features including the new 'Age_group' column\nencoder = OneHotEncoder(sparse_output=False, drop='first')\nencoded_columns = encoder.fit_transform(df[['education_level', 'Age_group']])\n\n# Create a DataFrame for the encoded columns and merge back into the dataset\nencoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(['education_level', 'Age_group']))\ndf = pd.concat([df, encoded_df], axis=1)\n\n# Drop the original 'education_level' and 'Age_group' columns after encoding\ndf.drop(columns=['education_level', 'Age_group'], inplace=True)\n\n# Test the transformations\nprint(\"Scaled numerical features:\")\nprint(df[numerical_features].head())\n\nprint(\"\\nOne-hot encoded categorical features:\")\nprint(encoded_df.head())\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'KeyError'>",
          "evalue": "\"['education_level'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Step 4: One-hot encode categorical features including the new 'Age_group' column\u001b[39;00m\n\u001b[1;32m     23\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m encoded_columns \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meducation_level\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAge_group\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for the encoded columns and merge back into the dataset\u001b[39;00m\n\u001b[1;32m     27\u001b[0m encoded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(encoded_columns, columns\u001b[38;5;241m=\u001b[39mencoder\u001b[38;5;241m.\u001b[39mget_feature_names_out([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meducation_level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge_group\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/indexes/base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['education_level'] not in index\""
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": "# Aggregating asset-related columns into a new 'total_assets' column\ndf['total_assets'] = df[['gained_asset', 'durable_asset', 'save_asset']].sum(axis=1)\nd()\n# Aggregating expense-related columns into a new 'total_expenses' column\ndf['total_expenses'] = df[['living_expenses', 'other_expenses', 'farm_expenses']].sum(axis=1)\n\n# Drop the original asset and expense columns if no longer needed\ndf.drop(columns=['gained_asset', 'durable_asset', 'save_asset', 'living_expenses', 'other_expenses', 'farm_expenses'], inplace=True)\n\n# Test the new columns\nprint(df[['total_assets', 'total_expenses']].hea)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'KeyError'>",
          "evalue": "\"None of [Index(['gained_asset', 'durable_asset', 'save_asset'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Aggregating asset-related columns into a new 'total_assets' column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_assets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgained_asset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdurable_asset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msave_asset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m d()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Aggregating expense-related columns into a new 'total_expenses' column\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/indexes/base.py:6248\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['gained_asset', 'durable_asset', 'save_asset'], dtype='object')] are in the [columns]\""
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}